{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:25:02.294570Z",
     "iopub.status.busy": "2025-10-09T08:25:02.294304Z",
     "iopub.status.idle": "2025-10-09T08:25:20.984735Z",
     "shell.execute_reply": "2025-10-09T08:25:20.983721Z",
     "shell.execute_reply.started": "2025-10-09T08:25:02.294550Z"
    },
    "executionInfo": {
     "elapsed": 7948,
     "status": "ok",
     "timestamp": 1759886354676,
     "user": {
      "displayName": "Kaushik Raj Nadar",
      "userId": "03682639286480228758"
     },
     "user_tz": -330
    },
    "id": "u1bWZo24Dd_F",
    "outputId": "15a38f25-162b-4308-b404-8617be457657",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AttentionMOI'...\n",
      "remote: Enumerating objects: 828, done.\u001b[K\n",
      "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
      "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
      "remote: Total 828 (delta 56), reused 118 (delta 27), pack-reused 647 (from 1)\u001b[K\n",
      "Receiving objects: 100% (828/828), 269.73 MiB | 16.99 MiB/s, done.\n",
      "Resolving deltas: 100% (364/364), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/BioAI-kits/AttentionMOI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:25:20.986574Z",
     "iopub.status.busy": "2025-10-09T08:25:20.986328Z",
     "iopub.status.idle": "2025-10-09T08:25:20.992509Z",
     "shell.execute_reply": "2025-10-09T08:25:20.991784Z",
     "shell.execute_reply.started": "2025-10-09T08:25:20.986554Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1759886817994,
     "user": {
      "displayName": "Kaushik Raj Nadar",
      "userId": "03682639286480228758"
     },
     "user_tz": -330
    },
    "id": "mzf5E3zoXbjN",
    "outputId": "96fd6102-89da-4f88-9b28-9622e8b1ebc7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/AttentionMOI\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/AttentionMOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:25:20.993505Z",
     "iopub.status.busy": "2025-10-09T08:25:20.993321Z",
     "iopub.status.idle": "2025-10-09T08:25:21.008743Z",
     "shell.execute_reply": "2025-10-09T08:25:21.008032Z",
     "shell.execute_reply.started": "2025-10-09T08:25:20.993491Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/AttentionMOI/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/kaggle/working/AttentionMOI/setup.py'\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "\n",
    "install_packages = [\n",
    "    'captum>=0.4.1',\n",
    "    'mygene>=3.2.2',\n",
    "    'openpyxl>=3.0.9',\n",
    "    'packaging>=21.3',\n",
    "    'pandas>=1.2.5',\n",
    "    'pandocfilters>=1.5.0',\n",
    "    'seaborn>=0.11.2',\n",
    "    'torch>=2',\n",
    "    'scikit-learn>=1.2.2',\n",
    "    'numpy>=1.23.5',\n",
    "    'matplotlib>=3.6.2',\n",
    "    'xgboost>=1.7.4',\n",
    "    'livelossplot', \n",
    "    'tensorboardX',\n",
    "    'tqdm',\n",
    "    'ipython',\n",
    "]\n",
    "\n",
    "setup(\n",
    "    # 应用名\n",
    "    name='AttentionMOI',\n",
    "    # 作者名\n",
    "    author='Billy',\n",
    "    # 作者邮箱\n",
    "    author_email='liangbilin0324@163.com',\n",
    "    # 版本号\n",
    "    version='0.1.2',\n",
    "    # 要求python版本\n",
    "    python_requires=\">=3.9\",\n",
    "    # 找到本目录下的所有python包\n",
    "    packages=find_packages(),\n",
    "    # 自动安装依赖\n",
    "    install_requires=install_packages,\n",
    "    dependency_links=[\n",
    "        \"https://pypi.org/simple/\",\n",
    "        \"https://download.pytorch.org/whl/cpu#egg=torch\",\n",
    "        ],\n",
    "    # 程序网站\n",
    "    url='https://github.com/BioAI-kits/AttentionMOI',\n",
    "    # 程序简单描述\n",
    "    description=\"A Denoised Multi-omics Integration Framework for Cancer Subtype Classification and Survival Prediction.\",\n",
    "    # 开源许可\n",
    "    license='Apache License 2.0',\n",
    "    # 包含的数据\n",
    "    data_files=['AttentionMOI/example/cnv.csv.gz', 'AttentionMOI/example/met.csv.gz', 'AttentionMOI/example/rna.csv.gz', 'AttentionMOI/example/label.csv'],\n",
    "    # 命令行\n",
    "    entry_points={\n",
    "        'console_scripts': ['moi = AttentionMOI.moi:run_main',\n",
    "                            ],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:25:22.802371Z",
     "iopub.status.busy": "2025-10-09T08:25:22.802066Z",
     "iopub.status.idle": "2025-10-09T08:25:22.808573Z",
     "shell.execute_reply": "2025-10-09T08:25:22.807822Z",
     "shell.execute_reply.started": "2025-10-09T08:25:22.802348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/AttentionMOI/AttentionMOI/deepmoi.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/kaggle/working/AttentionMOI/AttentionMOI/deepmoi.py'\n",
    "import argparse, warnings, sys\n",
    "import numpy as np\n",
    "from .src.main import run\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "                                     prog='AttentionMOI',\n",
    "                                     usage=\"The program is used to build machine/deep learning model with single/multi omics dataset.\",\n",
    "                                     description=\"\", \n",
    "                                     epilog=\"Example (Data can be downloaded from https://github.com/BioAI-kits/AttentionMOI ): \\nmoi -f GBM_exp.csv.gz -f GBM_met.csv.gz -f GBM_logRatio.csv.gz -n rna -n met -n cnv -l GBM_label.csv --FSD -m all -o GBM_Result \\n \",\n",
    "                                     formatter_class=argparse.RawTextHelpFormatter\n",
    "                                     )\n",
    "\n",
    "    # config\n",
    "    parser.add_argument('-f', '--omic_file', action='append', help='REQUIRED: File path for omics files (should be matrix)', required=True)\n",
    "    parser.add_argument('-n', '--omic_name', action='append',\n",
    "                        help='REQUIRED: Omic names for omics files, should be the same order as the omics file', required=True)\n",
    "    parser.add_argument('-l', '--label_file', help='REQUIRED: File path for label file', required=True)\n",
    "    parser.add_argument('-o', '--outdir', help='OPTIONAL: Setting output file path, default=./output', type=str, default='./output')\n",
    "    parser.add_argument('--clin_file', type=str, required=False, help='Path to the clinical data file (optional).')\n",
    "\n",
    "    # feature selection with distribution\n",
    "    parser.add_argument('-i', '--iteration', help='OPTIONAL: The number of FSD iterations (integer), default=10.', type=int, default=10)\n",
    "    parser.add_argument('-s', '--seed', help='OPTIONAL: Random seed for FSD (integer), default=0', type=int, default=0)\n",
    "    parser.add_argument('--threshold',\n",
    "                        help='OPTIONAL: FSD threshold to select features (float), default=0.8 (select features that are selected in 80 percent FSD iterations)',\n",
    "                        type=float, default=0.8)\n",
    "\n",
    "    # feature selection\n",
    "    parser.add_argument('--method', help='OPTIONAL: Method of feature selection, choosing from ANOVA, RFE, LASSO, PCA, default is no feature selection', type=str, default=None)\n",
    "    parser.add_argument('--percentile', help='OPTIONAL: Percent of features to keep for ANOVA (integer between 1-100), only used when using ANOVA, default=30', type=int, default=30)\n",
    "    parser.add_argument('--num_pc', help='OPTIONAL: Number of PCs to keep for PCA (integer), only used when using PCA, default=50', type=int, default=50)\n",
    "\n",
    "    # whether using FSD\n",
    "    parser.add_argument('--FSD', action=\"store_true\", help='OPTIONAL: Whether to use FSD to mitigate noise of omics. Default is not using FSD, and set --FSD to use FSD')\n",
    "\n",
    "    # building model\n",
    "    parser.add_argument('-t', '--test_size', help='OPTIONAL: Testing dataset proportion when split train test dataset (float), default=0.3 (30 percent data for testing)', type=float, default=0.3)\n",
    "    parser.add_argument('-b', '--batch', help='OPTIONAL: Mini-batch number for model training (integer), default=32', type=int, default=32)\n",
    "    parser.add_argument('-e', '--epoch', help='OPTIONAL: Epoch number for model training (integer), default=300', type=int, default=300)\n",
    "    parser.add_argument('-r', '--lr', help='OPTIONAL: Learning rate for model training(float), default=0.0001.', type=float, default=0.0001)\n",
    "    parser.add_argument('-w', '--weight_decay', help='OPTIONAL: weight_decay parameter for model training (float), default=0.0001', type=float,\n",
    "                        default=0.0001)\n",
    "\n",
    "    # different models\n",
    "    parser.add_argument('-m', '--model', help='OPTIONAL: Model names, choosing from DNN, Net (Net for AttentionMOI), RF, XGboost, svm, mogonet, moanna, default=DNN.', type=str, default=\"DNN\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    \n",
    "    if len(set((args.omic_name))) < 2 and args.model in ['Net', 'all']:\n",
    "        print('Single omic data cannot be used to construct the AttentionMOI model.')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    run(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:25:24.721920Z",
     "iopub.status.busy": "2025-10-09T08:25:24.721108Z",
     "iopub.status.idle": "2025-10-09T08:26:41.295306Z",
     "shell.execute_reply": "2025-10-09T08:26:41.294214Z",
     "shell.execute_reply.started": "2025-10-09T08:25:24.721892Z"
    },
    "executionInfo": {
     "elapsed": 8393,
     "status": "ok",
     "timestamp": 1759886827164,
     "user": {
      "displayName": "Kaushik Raj Nadar",
      "userId": "03682639286480228758"
     },
     "user_tz": -330
    },
    "id": "wQ4JCVkAiTml",
    "outputId": "f6613800-c9ac-4092-e0ad-81d5af5b5a85",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/AttentionMOI\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting captum>=0.4.1 (from AttentionMOI==0.1.2)\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting mygene>=3.2.2 (from AttentionMOI==0.1.2)\n",
      "  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: openpyxl>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (3.1.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (25.0)\n",
      "Requirement already satisfied: pandas>=1.2.5 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (1.5.1)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (0.12.2)\n",
      "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (3.7.2)\n",
      "Requirement already satisfied: xgboost>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (2.0.3)\n",
      "Collecting livelossplot (from AttentionMOI==0.1.2)\n",
      "  Downloading livelossplot-0.5.6-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting tensorboardX (from AttentionMOI==0.1.2)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (4.67.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from AttentionMOI==0.1.2) (7.34.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (11.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->AttentionMOI==0.1.2) (2.9.0.post0)\n",
      "Collecting biothings-client>=0.2.6 (from mygene>=3.2.2->AttentionMOI==0.1.2)\n",
      "  Downloading biothings_client-0.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->AttentionMOI==0.1.2) (2.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.0.9->AttentionMOI==0.1.2) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.5->AttentionMOI==0.1.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.5->AttentionMOI==0.1.2) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->AttentionMOI==0.1.2) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->AttentionMOI==0.1.2) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->AttentionMOI==0.1.2) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->AttentionMOI==0.1.2)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->AttentionMOI==0.1.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->AttentionMOI==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (75.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (3.0.51)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (2.19.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->AttentionMOI==0.1.2) (4.9.0)\n",
      "Requirement already satisfied: bokeh in /usr/local/lib/python3.11/dist-packages (from livelossplot->AttentionMOI==0.1.2) (3.7.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->AttentionMOI==0.1.2) (3.20.3)\n",
      "Requirement already satisfied: httpx>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (0.28.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->AttentionMOI==0.1.2) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->AttentionMOI==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->AttentionMOI==0.1.2) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->AttentionMOI==0.1.2) (1.17.0)\n",
      "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.11/dist-packages (from bokeh->livelossplot->AttentionMOI==0.1.2) (1.48.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh->livelossplot->AttentionMOI==0.1.2) (6.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh->livelossplot->AttentionMOI==0.1.2) (6.5.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh->livelossplot->AttentionMOI==0.1.2) (2025.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->AttentionMOI==0.1.2) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->AttentionMOI==0.1.2) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->AttentionMOI==0.1.2) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.5->AttentionMOI==0.1.2) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.5->AttentionMOI==0.1.2) (2024.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (0.16.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.5->AttentionMOI==0.1.2) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene>=3.2.2->AttentionMOI==0.1.2) (1.3.1)\n",
      "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading livelossplot-0.5.6-py3-none-any.whl (23 kB)\n",
      "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading biothings_client-0.4.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, biothings-client, mygene, tensorboardX, livelossplot, captum, AttentionMOI\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Running setup.py develop for AttentionMOI\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed AttentionMOI-0.1.2 biothings-client-0.4.1 captum-0.8.0 livelossplot-0.5.6 mygene-3.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorboardX-2.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T04:30:37.933209Z",
     "iopub.status.busy": "2025-10-09T04:30:37.932934Z",
     "iopub.status.idle": "2025-10-09T04:31:03.723857Z",
     "shell.execute_reply": "2025-10-09T04:31:03.723130Z",
     "shell.execute_reply.started": "2025-10-09T04:30:37.933183Z"
    },
    "executionInfo": {
     "elapsed": 12908,
     "status": "ok",
     "timestamp": 1759886701341,
     "user": {
      "displayName": "Kaushik Raj Nadar",
      "userId": "03682639286480228758"
     },
     "user_tz": -330
    },
    "id": "d0f393c5",
    "outputId": "3c432a66-7259-4240-e9d9-8136e2f50d12",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: The program is used to build machine/deep learning model with single/multi omics dataset.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f OMIC_FILE, --omic_file OMIC_FILE\n",
      "                        REQUIRED: File path for omics files (should be matrix)\n",
      "  -n OMIC_NAME, --omic_name OMIC_NAME\n",
      "                        REQUIRED: Omic names for omics files, should be the same order as the omics file\n",
      "  -l LABEL_FILE, --label_file LABEL_FILE\n",
      "                        REQUIRED: File path for label file\n",
      "  -o OUTDIR, --outdir OUTDIR\n",
      "                        OPTIONAL: Setting output file path, default=./output\n",
      "  --clin_file CLIN_FILE\n",
      "                        Path to the clinical data file (optional).\n",
      "  -i ITERATION, --iteration ITERATION\n",
      "                        OPTIONAL: The number of FSD iterations (integer), default=10.\n",
      "  -s SEED, --seed SEED  OPTIONAL: Random seed for FSD (integer), default=0\n",
      "  --threshold THRESHOLD\n",
      "                        OPTIONAL: FSD threshold to select features (float), default=0.8 (select features that are selected in 80 percent FSD iterations)\n",
      "  --method METHOD       OPTIONAL: Method of feature selection, choosing from ANOVA, RFE, LASSO, PCA, default is no feature selection\n",
      "  --percentile PERCENTILE\n",
      "                        OPTIONAL: Percent of features to keep for ANOVA (integer between 1-100), only used when using ANOVA, default=30\n",
      "  --num_pc NUM_PC       OPTIONAL: Number of PCs to keep for PCA (integer), only used when using PCA, default=50\n",
      "  --FSD                 OPTIONAL: Whether to use FSD to mitigate noise of omics. Default is not using FSD, and set --FSD to use FSD\n",
      "  -t TEST_SIZE, --test_size TEST_SIZE\n",
      "                        OPTIONAL: Testing dataset proportion when split train test dataset (float), default=0.3 (30 percent data for testing)\n",
      "  -b BATCH, --batch BATCH\n",
      "                        OPTIONAL: Mini-batch number for model training (integer), default=32\n",
      "  -e EPOCH, --epoch EPOCH\n",
      "                        OPTIONAL: Epoch number for model training (integer), default=300\n",
      "  -r LR, --lr LR        OPTIONAL: Learning rate for model training(float), default=0.0001.\n",
      "  -w WEIGHT_DECAY, --weight_decay WEIGHT_DECAY\n",
      "                        OPTIONAL: weight_decay parameter for model training (float), default=0.0001\n",
      "  -m MODEL, --model MODEL\n",
      "                        OPTIONAL: Model names, choosing from DNN, Net (Net for AttentionMOI), RF, XGboost, svm, mogonet, moanna, default=DNN.\n",
      "\n",
      "Example (Data can be downloaded from https://github.com/BioAI-kits/AttentionMOI ): \n",
      "moi -f GBM_exp.csv.gz -f GBM_met.csv.gz -f GBM_logRatio.csv.gz -n rna -n met -n cnv -l GBM_label.csv --FSD -m all -o GBM_Result \n",
      " \n"
     ]
    }
   ],
   "source": [
    "!moi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T04:31:03.726971Z",
     "iopub.status.busy": "2025-10-09T04:31:03.726522Z",
     "iopub.status.idle": "2025-10-09T04:31:03.732537Z",
     "shell.execute_reply": "2025-10-09T04:31:03.731819Z",
     "shell.execute_reply.started": "2025-10-09T04:31:03.726948Z"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1759886828725,
     "user": {
      "displayName": "Kaushik Raj Nadar",
      "userId": "03682639286480228758"
     },
     "user_tz": -330
    },
    "id": "EYjVmn8pmu6S",
    "outputId": "97a5eedf-e5b3-4774-b383-733c9b5f868c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/AttentionMOI/dataset/GBM\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/AttentionMOI/dataset/GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:26:41.297035Z",
     "iopub.status.busy": "2025-10-09T08:26:41.296793Z",
     "iopub.status.idle": "2025-10-09T08:26:41.305103Z",
     "shell.execute_reply": "2025-10-09T08:26:41.304313Z",
     "shell.execute_reply.started": "2025-10-09T08:26:41.297013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is: /kaggle/working/AttentionMOI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(f\"The current working directory is: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-09T12:25:11.002Z",
     "iopub.execute_input": "2025-10-09T08:26:47.009399Z",
     "iopub.status.busy": "2025-10-09T08:26:47.008657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned unique (omics,fsd,method,model) combos: 460\n",
      "Each combo runs 30 trials (single hold-out split per trial).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_outdir() missing 1 required positional argument: 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, N_TRIALS+\u001b[32m1\u001b[39m):\n\u001b[32m    215\u001b[39m         seed = BASE_SEED + (trial_idx) \n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         outdir = \u001b[43mmake_outdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT_OUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfsd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m         cmd    = build_cmd(omics, method, fsd, model, outdir, TEST_SIZE, seed, EPOCHS)\n\u001b[32m    220\u001b[39m         \u001b[38;5;66;03m# Run the AttentionMOI CLI\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: make_outdir() missing 1 required positional argument: 'seed'"
     ]
    }
   ],
   "source": [
    "# === Master driver for GBM permutations (AttentionMOI CLI only) ===\n",
    "# - Runs all omic subsets (rna, met, cnv), with/without FSD, all FS methods, all models\n",
    "# - Emulates K-fold via repeated runs with different seeds (since repo uses train_test_split)\n",
    "# - Collects per-epoch/per-run metrics from outdir/log.txt and outdir/evaluation.txt into CSVs\n",
    "\n",
    "import os,  re, shlex, subprocess\n",
    "#import sys, itertools,json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths & basic parameters\n",
    "# ----------------------------\n",
    "BASE = Path(\"/Users/kaushikrajnadar/Downloads/AttentionMOI-master/AttentionMOI/example\")  # you said this is where you are\n",
    "assert BASE.exists(), f\"Not found: {BASE}\"\n",
    "\n",
    "FILES = {\n",
    "    \"rna\": str(BASE / \"GBM_exp.csv.gz\"),\n",
    "    \"met\": str(BASE / \"GBM_met.csv.gz\"),\n",
    "    \"cnv\": str(BASE / \"GBM_cnv_logRatio.csv.gz\"),\n",
    "}\n",
    "LABEL = str(BASE / \"GBM_label.csv\")\n",
    "\n",
    "# Global output bucket that will contain one subfolder per run\n",
    "ROOT_OUT = BASE / \"GBM_Result_AllRuns\"\n",
    "ROOT_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Controls\n",
    "#K_FOLDS   = 5          # emulate 5-fold by 5 seeds per trial\n",
    "N_TRIALS  = 30         # set to 30 for the paper-style violin distribution; smaller for quick pass\n",
    "TEST_SIZE = 0.30\n",
    "EPOCHS_DNN    = 100    # epochs for DNN/Net (ignored by RF/XGB/SVM/MOANNA/MOGONET)\n",
    "BASE_SEED = 2025\n",
    "\n",
    "# Choose omic subsets, FS methods, FSD on/off, and models\n",
    "OMIC_SUBSETS = [\n",
    "    [\"rna\"], [\"met\"], [\"cnv\"],\n",
    "    [\"rna\",\"met\"], [\"rna\",\"cnv\"], [\"met\",\"cnv\"],\n",
    "    [\"rna\",\"met\",\"cnv\"],\n",
    "]\n",
    "FS_METHODS = [None, \"ANOVA\", \"RFE\", \"LASSO\", \"PCA\"]\n",
    "FSD_FLAGS  = [False, True]\n",
    "MODELS = [\"DNN\", \"Net\", \"RF\", \"XGboost\", \"svm\", \"moanna\", \"mogonet\"]\n",
    "\n",
    "# Utility: skip invalid combos (Net requires >=2 omics)\n",
    "def valid_combo(model, omics):\n",
    "    if model == \"Net\" and len(set(omics)) < 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Utility: build a unique outdir name for one run\n",
    "def make_outdir(root_out, omics, fsd, method, model, trial_idx, fold_idx, seed):\n",
    "    omic_tag = \"-\".join(omics)\n",
    "    fsd_tag  = \"FSD\" if fsd else \"NoFSD\"\n",
    "    mth_tag  = \"None\" if method is None else method\n",
    "    run_tag  = f\"trial{trial_idx:02d}_fold{fold_idx:02d}_seed{seed}\"\n",
    "    outdir   = root_out / omic_tag / fsd_tag / mth_tag / model / run_tag\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    return outdir\n",
    "\n",
    "# Utility: assemble the moi command respecting repo’s flags\n",
    "def build_cmd(omics, method, fsd, model, outdir, test_size, seed, epochs):\n",
    "    cmd = [\"moi\"]\n",
    "    # -f / -n (files and names must be in the same order)\n",
    "    for om in omics:\n",
    "        cmd += [\"-f\", FILES[om]]\n",
    "    for om in omics:\n",
    "        cmd += [\"-n\", om]\n",
    "    # labels\n",
    "    cmd += [\"-l\", LABEL]\n",
    "    # common settings\n",
    "    cmd += [\"-o\", str(outdir)]\n",
    "    cmd += [\"-t\", str(test_size)]\n",
    "    cmd += [\"-s\", str(seed)]                 # seed controls FSD and train_test_split()\n",
    "    cmd += [\"-e\", str(epochs)]               # epochs (used by DNN/Net)\n",
    "    # FSD\n",
    "    if fsd:\n",
    "        cmd += [\"--FSD\", \"-i\", \"10\", \"--threshold\", \"0.8\"]  # default FSD knobs\n",
    "    # FS method\n",
    "    if method is not None:\n",
    "        cmd += [\"--method\", method]\n",
    "        if method == \"ANOVA\":\n",
    "            cmd += [\"--percentile\", \"30\"]\n",
    "        if method == \"PCA\":\n",
    "            cmd += [\"--num_pc\", \"50\"]\n",
    "    # Model\n",
    "    cmd += [\"-m\", model]\n",
    "    return cmd\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Parsers for repo logs\n",
    "# ----------------------------\n",
    "\n",
    "# DNN/Net epoch line examples (train.py):\n",
    "# Train: \"Epoch 10 | Train Loss 0.2965718934 | Train_ACC 0.932 | Train_AUC 0.985 | Train_F1_score 0.909 | Train_Recall 0.925 | Train_Precision 0.897\"\n",
    "# Test:  \"Epoch 10 | Test Loss  0.1234567890 | Test_ACC  0.900 | Test_AUC  0.920 | Test_F1_score  0.880 | Test_Recall  0.860 | Test_Precision  0.905\"\n",
    "\n",
    "re_epoch_train = re.compile(\n",
    "    r\"Epoch\\s+(\\d+)\\s+\\|\\s+Train Loss\\s+([0-9\\.Ee+-]+)\\s+\\|\\s+Train_ACC\\s+([0-9\\.]+)\\s+\\|\\s+Train_AUC\\s+([0-9\\.]+)\\s+\\|\\s+Train_F1_score\\s+([0-9\\.]+)\\s+\\|\\s+Train_Recall\\s+([0-9\\.]+)\\s+\\|\\s+Train_Precision\\s+([0-9\\.]+)\"\n",
    ")\n",
    "re_epoch_test  = re.compile(\n",
    "    r\"Epoch\\s+(\\d+)\\s+\\|\\s+Test Loss\\s+([0-9\\.Ee+-]+)\\s+\\|\\s+Test_ACC\\s+([0-9\\.]+)\\s+\\|\\s+Test_AUC\\s+([0-9\\.]+)\\s+\\|\\s+Test_F1_score\\s+([0-9\\.]+)\\s+\\|\\s+Test_Recall\\s+([0-9\\.]+)\\s+\\|\\s+Test_Precision\\s+([0-9\\.]+)\"\n",
    ")\n",
    "\n",
    "# ML one-shot metrics (RF/XGboost/SVM) also appear in log.txt:\n",
    "# \"Train_ACC 0.932 | Train_AUC 0.985 | Train_F1_score 0.909 | Train_Recall 0.925 | Train_Precision 0.897\"\n",
    "# \"Test_ACC  0.900 | Test_AUC  0.920 | Test_F1_score  0.880 | Test_Recall  0.860 | Test_Precision  0.905\"\n",
    "re_ml_train = re.compile(\n",
    "    r\"Train_ACC\\s+([0-9\\.]+)\\s+\\|\\s+Train_AUC\\s+([0-9\\.]+)\\s+\\|\\s+Train_F1_score\\s+([0-9\\.]+)\\s+\\|\\s+Train_Recall\\s+([0-9\\.]+)\\s+\\|\\s+Train_Precision\\s+([0-9\\.]+)\"\n",
    ")\n",
    "re_ml_test = re.compile(\n",
    "    r\"Test_ACC\\s+([0-9\\.]+)\\s+\\|\\s+Test_AUC\\s+([0-9\\.]+)\\s+\\|\\s+Test_F1_score\\s+([0-9\\.]+)\\s+\\|\\s+Test_Recall\\s+([0-9\\.]+)\\s+\\|\\s+Test_Precision\\s+([0-9\\.]+)\"\n",
    ")\n",
    "\n",
    "def parse_log_epochs(log_path, model):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of per-epoch metrics when available (DNN/Net),\n",
    "    or single-row entries for ML models (RF/XGboost/SVM/MOANNA/MOGONET).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if not Path(log_path).exists():\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    with open(log_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # DNN/Net epoch lines\n",
    "            m = re_epoch_train.search(line)\n",
    "            if m:\n",
    "                ep, loss, acc, auc, f1, rec, prec = m.groups()\n",
    "                rows.append(dict(\n",
    "                    epoch=int(ep), split=\"Train\",\n",
    "                    loss=float(loss), acc=float(acc), auc=float(auc),\n",
    "                    f1=float(f1), recall=float(rec), precision=float(prec)\n",
    "                ))\n",
    "                continue\n",
    "            m = re_epoch_test.search(line)\n",
    "            if m:\n",
    "                ep, loss, acc, auc, f1, rec, prec = m.groups()\n",
    "                rows.append(dict(\n",
    "                    epoch=int(ep), split=\"Test\",\n",
    "                    loss=float(loss), acc=float(acc), auc=float(auc),\n",
    "                    f1=float(f1), recall=float(rec), precision=float(prec)\n",
    "                ))\n",
    "                continue\n",
    "            # ML one-shot lines\n",
    "            if model in [\"RF\", \"XGboost\", \"svm\", \"moanna\", \"mogonet\"]:\n",
    "                mt = re_ml_train.search(line)\n",
    "                if mt:\n",
    "                    acc, auc, f1, rec, prec = mt.groups()\n",
    "                    rows.append(dict(\n",
    "                        epoch=1, split=\"Train\",\n",
    "                        loss=None, acc=float(acc), auc=float(auc),\n",
    "                        f1=float(f1), recall=float(rec), precision=float(prec)\n",
    "                    ))\n",
    "                    continue\n",
    "                mt = re_ml_test.search(line)\n",
    "                if mt:\n",
    "                    acc, auc, f1, rec, prec = mt.groups()\n",
    "                    rows.append(dict(\n",
    "                        epoch=1, split=\"Test\",\n",
    "                        loss=None, acc=float(acc), auc=float(auc),\n",
    "                        f1=float(f1), recall=float(rec), precision=float(prec)\n",
    "                    ))\n",
    "                    continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# evaluation.txt lines look like:\n",
    "# \"{model}\\t{FS_desc}\\t{omic_names}\\t{acc}\\t{prec}\\t{f1}\\t{auc}\\t{recall}\"\n",
    "def parse_evaluation_txt(eval_path):\n",
    "    if not Path(eval_path).exists():\n",
    "        return None\n",
    "    lines = [l.strip() for l in open(eval_path, \"r\").read().splitlines() if l.strip()]\n",
    "    if not lines:\n",
    "        return None\n",
    "    # take the LAST non-empty line (this run)\n",
    "    parts = lines[-1].split(\"\\t\")\n",
    "    if len(parts) < 8:\n",
    "        return None\n",
    "    model, fs_desc, omic_desc, acc, prec, f1, auc, recall = parts[:8]\n",
    "    return dict(model=model, fs_desc=fs_desc, omic_desc=omic_desc,\n",
    "                acc=float(acc), prec=float(prec), f1=float(f1),\n",
    "                auc=float(auc), recall=float(recall))\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Main sweep\n",
    "# ----------------------------\n",
    "all_epoch_rows = []\n",
    "all_run_rows   = []\n",
    "\n",
    "# Configure a base seed so trial t, fold k seed is reproducible but distinct\n",
    "BASE_SEED = 2025\n",
    "\n",
    "total_plans = 0\n",
    "for omics in OMIC_SUBSETS:\n",
    "    for fsd in FSD_FLAGS:\n",
    "        for method in FS_METHODS:\n",
    "            for model in MODELS:\n",
    "                if not valid_combo(model, omics):\n",
    "                    continue\n",
    "                total_plans += 1\n",
    "\n",
    "print(f\"Planned unique (omics,fsd,method,model) combos: {total_plans}\")\n",
    "print(f\"Each combo runs {N_TRIALS} trials (single hold-out split per trial).\")\n",
    "\n",
    "for omics in OMIC_SUBSETS:\n",
    "    for fsd in FSD_FLAGS:\n",
    "        for method in FS_METHODS:\n",
    "            for model in MODELS:\n",
    "                if not valid_combo(model, omics):\n",
    "                    continue\n",
    "\n",
    "                for trial_idx in range(1, N_TRIALS+1):\n",
    "                   \n",
    "                        seed = BASE_SEED + (trial_idx) \n",
    "\n",
    "                        outdir = make_outdir(ROOT_OUT, omics, fsd, method, model, trial_idx, seed)\n",
    "                        cmd    = build_cmd(omics, method, fsd, model, outdir, TEST_SIZE, seed, EPOCHS)\n",
    "\n",
    "                        # Run the AttentionMOI CLI\n",
    "                        print(\"\\n==> RUN:\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "                        res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "                        # Persist raw stdout for debugging\n",
    "                        (outdir/\"stdout.txt\").write_text(res.stdout)\n",
    "\n",
    "                        # Parse logs to per-epoch CSV\n",
    "                        log_path  = outdir/\"log.txt\"\n",
    "                        eval_path = outdir/\"evaluation.txt\"\n",
    "\n",
    "                        ep_df = parse_log_epochs(log_path, model)\n",
    "                        if not ep_df.empty:\n",
    "                            # annotate with run metadata\n",
    "                            ep_df.insert(0, \"model\", model)\n",
    "                            ep_df.insert(0, \"method\", \"None\" if method is None else method)\n",
    "                            ep_df.insert(0, \"fsd\", int(fsd))\n",
    "                            ep_df.insert(0, \"omics\", \"-\".join(omics))\n",
    "                            ep_df.insert(0, \"trial\", trial_idx)\n",
    "                            ep_df.insert(0, \"fold\", fold_idx)\n",
    "                            ep_df.to_csv(outdir/\"epoch_metrics.csv\", index=False)\n",
    "                            all_epoch_rows.append(ep_df)\n",
    "\n",
    "                        # Parse evaluation.txt to per-run summary CSV\n",
    "                        run_rec = parse_evaluation_txt(eval_path)\n",
    "                        if run_rec is not None:\n",
    "                            run_rec.update(dict(\n",
    "                                omics=\"-\".join(omics),\n",
    "                                fsd=int(fsd),\n",
    "                                method=\"None\" if method is None else method,\n",
    "                                model=model,\n",
    "                                trial=trial_idx,\n",
    "                                seed=seed,\n",
    "                                outdir=str(outdir),\n",
    "                            ))\n",
    "                            # write a small run_summary.csv in the outdir\n",
    "                            pd.DataFrame([run_rec]).to_csv(outdir/\"run_summary.csv\", index=False)\n",
    "                            all_run_rows.append(run_rec)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Write global aggregators\n",
    "# ----------------------------\n",
    "if all_epoch_rows:\n",
    "    epochs_all = pd.concat(all_epoch_rows, ignore_index=True)\n",
    "    epochs_all.to_csv(ROOT_OUT/\"ALL_epoch_metrics.csv\", index=False)\n",
    "    print(\"Wrote:\", ROOT_OUT/\"ALL_epoch_metrics.csv\")\n",
    "\n",
    "if all_run_rows:\n",
    "    runs_all = pd.DataFrame(all_run_rows)\n",
    "    runs_all.to_csv(ROOT_OUT/\"ALL_run_summaries.csv\", index=False)\n",
    "    print(\"Wrote:\", ROOT_OUT/\"ALL_run_summaries.csv\")\n",
    "\n",
    "print(\"DONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5AcGDURSii1PfZk+m2cox",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
